{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Algoritmos para Big Data\n",
    "\n",
    "**Handout 2 -  Data joining, windowing, and Spark SQL**\n",
    "\n",
    "**2024/25**\n",
    "\n",
    "This lab class aims to get hands-on experience on three issues related to data processing: data joining, data windowing and Spark SQL.\n",
    "\n",
    "This notebook should contain the implementation of the tasks presented in the handout.\n",
    "\n",
    "Hence both handout and notebook must be considered together as one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task A - Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datasest**\n",
    "\n",
    "The file can be downloaded from\n",
    "\n",
    "https://bigdata.iscte-iul.eu/datasets/retail-data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = '/opt/conda/envs/vscode_pyspark/bin/python3'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/opt/conda/envs/vscode_pyspark/bin/python3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spark setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SparkSession\n",
    "spark = SparkSession.builder.appName(\"JoinWindowingSQL\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading and checking data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvoiceNo;StockCode;Description;Quantity;InvoiceDate;UnitPrice;CustomerID;Country\n",
      "536375;71053;WHITE METAL LANTERN;6;01/12/2010 09:32;3.39;17850;United Kingdom\n",
      "C536391;21983;PACK OF 12 BLUE PAISLEY TISSUES ;-24;01/12/2010 10:24;0.29;17548;United Kingdom\n",
      "536395;21314;SMALL GLASS HEART TRINKET POT;8;01/12/2010 10:47;2.1;13767;United Kingdom\n",
      "536396;82494L;WOODEN FRAME ANTIQUE WHITE ;12;01/12/2010 10:51;2.55;17850;United Kingdom\n",
      "536425;22837;HOT WATER BOTTLE BABUSHKA ;8;01/12/2010 12:08;4.65;13758;United Kingdom\n",
      "536464;20878;SET/9 CHRISTMAS T-LIGHTS SCENTED ;1;01/12/2010 12:23;1.25;17968;France\n",
      "536520;22760;TRAY, BREAKFAST IN BED;1;01/12/2010 12:43;12.75;14729;United Kingdom\n",
      "536520;22812;PACK 3 BOXES CHRISTMAS PANNETONE;3;01/12/2010 12:43;1.95;14729;United Kingdom\n",
      "536530;21071;VINTAGE BILLBOARD DRINK ME MUG;24;01/12/2010 13:21;1.25;17905;France\n"
     ]
    }
   ],
   "source": [
    "# Reading data\n",
    "data_dir ='../datasets/'\n",
    "file_retail = data_dir + 'retail-data.csv'\n",
    "\n",
    "! head $file_retail\n",
    "df_retail = spark.read.csv(file_retail, header=True, sep=';', inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+----------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|     InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+----------------+---------+----------+--------------+\n",
      "|   536375|    71053| WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|United Kingdom|\n",
      "|  C536391|    21983|PACK OF 12 BLUE P...|     -24|01/12/2010 10:24|     0.29|     17548|United Kingdom|\n",
      "|   536395|    21314|SMALL GLASS HEART...|       8|01/12/2010 10:47|      2.1|     13767|United Kingdom|\n",
      "|   536396|   82494L|WOODEN FRAME ANTI...|      12|01/12/2010 10:51|     2.55|     17850|United Kingdom|\n",
      "|   536425|    22837|HOT WATER BOTTLE ...|       8|01/12/2010 12:08|     4.65|     13758|United Kingdom|\n",
      "|   536464|    20878|SET/9 CHRISTMAS T...|       1|01/12/2010 12:23|     1.25|     17968|        France|\n",
      "|   536520|    22760|TRAY, BREAKFAST I...|       1|01/12/2010 12:43|    12.75|     14729|United Kingdom|\n",
      "|   536520|    22812|PACK 3 BOXES CHRI...|       3|01/12/2010 12:43|     1.95|     14729|United Kingdom|\n",
      "|   536530|    21071|VINTAGE BILLBOARD...|      24|01/12/2010 13:21|     1.25|     17905|        France|\n",
      "|   536530|    22943|CHRISTMAS LIGHTS ...|       2|01/12/2010 13:21|     4.95|     17905|        France|\n",
      "+---------+---------+--------------------+--------+----------------+---------+----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "df_retail - number of rows is 3054.\n",
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_retail.show(10)\n",
    "print(f\"df_retail - number of rows is {df_retail.count()}.\")\n",
    "df_retail.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_retail - number of rows is 3054; after dropDuplicates() applied would be 3054.\n"
     ]
    }
   ],
   "source": [
    "print(f\"df_retail - number of rows is {df_retail.count()}; after dropDuplicates() applied would be {df_retail.dropDuplicates().count()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_retail - number of rows after dropna(how='any') would be 3054.\n"
     ]
    }
   ],
   "source": [
    "print(f'''df_retail - number of rows after dropna(how='any') would be {df_retail.dropna(how='any').count()}.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking nulls at each column of df_retail\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'InvoiceNo': 0,\n",
       " 'StockCode': 0,\n",
       " 'Description': 0,\n",
       " 'Quantity': 0,\n",
       " 'InvoiceDate': 0,\n",
       " 'UnitPrice': 0,\n",
       " 'CustomerID': 0,\n",
       " 'Country': 0}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Checking nulls at each column of df_retail')\n",
    "dict_nulls_retail = {col: df_retail.filter(df_retail[col].isNull()).count() for col in df_retail.columns}\n",
    "dict_nulls_retail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data seems fine!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task B - Data joining\n",
    "\n",
    "Combining rows from two DataFrames, based on one common column. Types of operation to consider are:\n",
    "- Inner join\n",
    "- Left join\n",
    "- Full join\n",
    "- Cross join\n",
    "- Anti join\n",
    "\n",
    "Based on df_retail, three DataFrames will be created:\n",
    "- df_sales, as df_retail but excluding column Country\n",
    "- df_customers, with two columns: CustomerID and Country\n",
    "- df_customers_nonUK, likewise df_costumers but filtering out the customers from United Kingdom\n",
    "\n",
    "\n",
    "Common column as condition will be CustomerID.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|       Country|count|\n",
      "+--------------+-----+\n",
      "|       Germany|  116|\n",
      "|        France|  490|\n",
      "|          EIRE|   48|\n",
      "|        Norway|   95|\n",
      "|     Australia|  111|\n",
      "|United Kingdom| 2162|\n",
      "|   Netherlands|   32|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_retail.groupBy('Country').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As df_retail but excluding the column Country\n",
    "df_sales = df_retail.drop('Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|       Country|count|\n",
      "+--------------+-----+\n",
      "|       Germany|    4|\n",
      "|        France|   15|\n",
      "|          EIRE|    2|\n",
      "|        Norway|    2|\n",
      "|     Australia|    4|\n",
      "|United Kingdom|  100|\n",
      "|   Netherlands|    2|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After df_retail but with just two columns: CustomerID and Country\n",
    "df_customers = df_retail.select('CustomerID', 'Country').distinct().orderBy('Country')\n",
    "df_customers.groupBy('Country').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_customers_nonUK - number of rows is 29.\n"
     ]
    }
   ],
   "source": [
    "# Likewise df_customers but filtering out the customers from United Kingdom\n",
    "df_customers_nonUK = df_customers.filter(F.col('Country') != 'United Kingdom') \n",
    "print(f'df_customers_nonUK - number of rows is {df_customers_nonUK.count()}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+--------------------+--------+----------------+---------+---------+\n",
      "|CustomerID|InvoiceNo|StockCode|         Description|Quantity|     InvoiceDate|UnitPrice|  Country|\n",
      "+----------+---------+---------+--------------------+--------+----------------+---------+---------+\n",
      "|     17968|   536464|    20878|SET/9 CHRISTMAS T...|       1|01/12/2010 12:23|     1.25|   France|\n",
      "|     17905|   536530|    21071|VINTAGE BILLBOARD...|      24|01/12/2010 13:21|     1.25|   France|\n",
      "|     17905|   536530|    22943|CHRISTMAS LIGHTS ...|       2|01/12/2010 13:21|     4.95|   France|\n",
      "|     12433|   536532|    22534|MAGIC DRAWING SLA...|      24|01/12/2010 13:24|     0.42|   Norway|\n",
      "|     22578|   536592|    22472|TV DINNER TRAY DO...|       3|01/12/2010 17:06|    11.02|  Germany|\n",
      "|     22578|   536592|    22620|4 TRADITIONAL SPI...|       2|01/12/2010 17:06|     2.51|  Germany|\n",
      "|     19997|   536592|   84536B|FAIRY CAKES NOTEB...|       1|01/12/2010 17:06|     0.85|Australia|\n",
      "|     21587|   536592|   85199L|LARGE HANGING IVO...|       1|01/12/2010 17:06|     1.28|   France|\n",
      "|     19555|   536592|   90214A|\"\"\"LETTER \"\"\"\"A\"\"...|       2|01/12/2010 17:06|     0.85|   France|\n",
      "|     19888|   536592|    20668|DISCO BALL CHRIST...|       6|01/12/2010 17:06|     0.43|Australia|\n",
      "+----------+---------+---------+--------------------+--------+----------------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Inner join - number of rows is 892.\n"
     ]
    }
   ],
   "source": [
    "# Inner join\n",
    "df = df_sales.join(df_customers_nonUK, on='CustomerID',how='inner')\n",
    "df.show(10)\n",
    "print(f'Inner join - number of rows is {df.count()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+--------------------+--------+----------------+---------+-------+\n",
      "|CustomerID|InvoiceNo|StockCode|         Description|Quantity|     InvoiceDate|UnitPrice|Country|\n",
      "+----------+---------+---------+--------------------+--------+----------------+---------+-------+\n",
      "|     17850|   536375|    71053| WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|   NULL|\n",
      "|     17548|  C536391|    21983|PACK OF 12 BLUE P...|     -24|01/12/2010 10:24|     0.29|   NULL|\n",
      "|     13767|   536395|    21314|SMALL GLASS HEART...|       8|01/12/2010 10:47|      2.1|   NULL|\n",
      "|     17850|   536396|   82494L|WOODEN FRAME ANTI...|      12|01/12/2010 10:51|     2.55|   NULL|\n",
      "|     13758|   536425|    22837|HOT WATER BOTTLE ...|       8|01/12/2010 12:08|     4.65|   NULL|\n",
      "|     17968|   536464|    20878|SET/9 CHRISTMAS T...|       1|01/12/2010 12:23|     1.25| France|\n",
      "|     14729|   536520|    22760|TRAY, BREAKFAST I...|       1|01/12/2010 12:43|    12.75|   NULL|\n",
      "|     14729|   536520|    22812|PACK 3 BOXES CHRI...|       3|01/12/2010 12:43|     1.95|   NULL|\n",
      "|     17905|   536530|    21071|VINTAGE BILLBOARD...|      24|01/12/2010 13:21|     1.25| France|\n",
      "|     17905|   536530|    22943|CHRISTMAS LIGHTS ...|       2|01/12/2010 13:21|     4.95| France|\n",
      "+----------+---------+---------+--------------------+--------+----------------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Left join - number of rows is 3054.\n"
     ]
    }
   ],
   "source": [
    "# Left join\n",
    "df = df_sales.join(df_customers_nonUK, on='CustomerID', how='left')\n",
    "df.show(10)\n",
    "print(f'Left join - number of rows is {df.count()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+--------------------+--------+----------------+---------+---------+\n",
      "|CustomerID|InvoiceNo|StockCode|         Description|Quantity|     InvoiceDate|UnitPrice|  Country|\n",
      "+----------+---------+---------+--------------------+--------+----------------+---------+---------+\n",
      "|     12431|   536389|    22941|CHRISTMAS LIGHTS ...|       6|01/12/2010 10:03|      8.5|Australia|\n",
      "|     12431|   536389|    22193|RED DINER WALL CLOCK|       2|01/12/2010 10:03|      8.5|Australia|\n",
      "|     12431|   536389|    21791|VINTAGE HEADS AND...|      12|01/12/2010 10:03|     1.25|Australia|\n",
      "|     12431|   536389|    22726|ALARM CLOCK BAKEL...|       4|01/12/2010 10:03|     3.75|Australia|\n",
      "|     12431|   536389|    22727|ALARM CLOCK BAKEL...|       4|01/12/2010 10:03|     3.75|Australia|\n",
      "|     12431|   536389|    22195|LARGE HEART MEASU...|      24|01/12/2010 10:03|     1.65|Australia|\n",
      "|     12431|   536389|   35004G|SET OF 3 GOLD FLY...|       4|01/12/2010 10:03|     6.35|Australia|\n",
      "|     12431|   536389|   85014B|RED RETROSPOT UMB...|       6|01/12/2010 10:03|     5.95|Australia|\n",
      "|     12431|   536389|   85014A|BLACK/BLUE POLKAD...|       3|01/12/2010 10:03|     5.95|Australia|\n",
      "|     12431|   536389|    22191|IVORY DINER WALL ...|       2|01/12/2010 10:03|      8.5|Australia|\n",
      "+----------+---------+---------+--------------------+--------+----------------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Full join - number of rows is 3054.\n"
     ]
    }
   ],
   "source": [
    "# Full join\n",
    "df = df_sales.join(df_customers_nonUK, on='CustomerID', how='full')\n",
    "df.show(10)\n",
    "print(f'Full join - number of rows is {df.count()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+--------+----------------+---------+----------+----------+-----------+\n",
      "|InvoiceNo|StockCode|        Description|Quantity|     InvoiceDate|UnitPrice|CustomerID|CustomerID|    Country|\n",
      "+---------+---------+-------------------+--------+----------------+---------+----------+----------+-----------+\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     19588|Netherlands|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     18444|     France|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     19888|  Australia|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     20145|  Australia|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     21365|    Germany|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     17873|     France|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     19997|  Australia|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     24111|     Norway|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     21587|     France|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     12662|    Germany|\n",
      "+---------+---------+-------------------+--------+----------------+---------+----------+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Cross join - number of rows is 88566.\n"
     ]
    }
   ],
   "source": [
    "# Cross join\n",
    "spark.conf.set(\"spark.sql.crossJoin.enabled\", \"true\")\n",
    "\n",
    "df = df_sales.crossJoin(df_customers_nonUK)\n",
    "df.show(10)\n",
    "print(f'Cross join - number of rows is {df.count()}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+--------------------+--------+----------------+---------+\n",
      "|CustomerID|InvoiceNo|StockCode|         Description|Quantity|     InvoiceDate|UnitPrice|\n",
      "+----------+---------+---------+--------------------+--------+----------------+---------+\n",
      "|     17850|   536375|    71053| WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|\n",
      "|     17548|  C536391|    21983|PACK OF 12 BLUE P...|     -24|01/12/2010 10:24|     0.29|\n",
      "|     13767|   536395|    21314|SMALL GLASS HEART...|       8|01/12/2010 10:47|      2.1|\n",
      "|     17850|   536396|   82494L|WOODEN FRAME ANTI...|      12|01/12/2010 10:51|     2.55|\n",
      "|     13758|   536425|    22837|HOT WATER BOTTLE ...|       8|01/12/2010 12:08|     4.65|\n",
      "|     14729|   536520|    22760|TRAY, BREAKFAST I...|       1|01/12/2010 12:43|    12.75|\n",
      "|     14729|   536520|    22812|PACK 3 BOXES CHRI...|       3|01/12/2010 12:43|     1.95|\n",
      "|     19224|   536544|    22812|PACK 3 BOXES CHRI...|       2|01/12/2010 14:32|     4.21|\n",
      "|     18657|   536544|   47593B|SCOTTIE DOGS BABY...|       2|01/12/2010 14:32|     0.85|\n",
      "|     17346|   536551|    22551|PLASTERS IN TIN S...|       1|01/12/2010 14:34|     1.65|\n",
      "+----------+---------+---------+--------------------+--------+----------------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Anti join - number of rows is 2162.\n"
     ]
    }
   ],
   "source": [
    "# Anti join\n",
    "df = df_sales.join(df_customers_nonUK, on='CustomerID', how='anti')\n",
    "df.show(10)\n",
    "print(f'Anti join - number of rows is {df.count()}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task C - Data windowing\n",
    "\n",
    "In relation to a column value (quantity x unit price), and considering a window with some size, how to compute:\n",
    "- a new column whose value is equal to the sum of the current row and previous rows?\n",
    "- the lag?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+--------------+------------------+\n",
      "|     InvoiceDate|CustomerID|       Country|             Value|\n",
      "+----------------+----------+--------------+------------------+\n",
      "|01/12/2010 08:26|     17850|United Kingdom|              15.3|\n",
      "|01/12/2010 08:26|     17850|United Kingdom|             20.34|\n",
      "|01/12/2010 08:26|     17850|United Kingdom|15.299999999999999|\n",
      "|01/12/2010 08:26|     17850|United Kingdom|              25.5|\n",
      "|01/12/2010 08:26|     17850|United Kingdom|              22.0|\n",
      "|01/12/2010 08:26|     17850|United Kingdom|             20.34|\n",
      "|01/12/2010 08:26|     17850|United Kingdom|             20.34|\n",
      "|01/12/2010 08:28|     17850|United Kingdom|11.100000000000001|\n",
      "|01/12/2010 08:28|     17850|United Kingdom|11.100000000000001|\n",
      "|01/12/2010 08:34|     13047|United Kingdom|             17.85|\n",
      "|01/12/2010 08:34|     13047|United Kingdom|              30.0|\n",
      "|01/12/2010 08:34|     13047|United Kingdom|              31.8|\n",
      "|01/12/2010 08:34|     13047|United Kingdom|              31.8|\n",
      "|01/12/2010 08:34|     13047|United Kingdom| 9.899999999999999|\n",
      "|01/12/2010 08:34|     13047|United Kingdom|              19.9|\n",
      "|01/12/2010 08:34|     13047|United Kingdom|14.850000000000001|\n",
      "|01/12/2010 08:34|     13047|United Kingdom|14.850000000000001|\n",
      "|01/12/2010 08:34|     13047|United Kingdom|              25.5|\n",
      "|01/12/2010 08:34|     13047|United Kingdom|14.850000000000001|\n",
      "|01/12/2010 08:34|     13047|United Kingdom|14.850000000000001|\n",
      "+----------------+----------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add value column as quantity * unit price, and then ordered by invoice date\n",
    "df_invoice_value = ( df_retail\n",
    "             .withColumn('Value', F.col('Quantity') * F.col('UnitPrice'))\n",
    "             .orderBy('InvoiceDate', ascending=True)\n",
    "             .select('InvoiceDate', 'CustomerID', 'Country', 'Value')\n",
    ")\n",
    "df_invoice_value.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+---------+------------------+-----------------------+\n",
      "|     InvoiceDate|CustomerID|  Country|             Value|SumLastSalesForCustomer|\n",
      "+----------------+----------+---------+------------------+-----------------------+\n",
      "|01/12/2010 10:03|     12431|Australia|              51.0|                   51.0|\n",
      "|01/12/2010 10:03|     12431|Australia|              17.0|                   68.0|\n",
      "|01/12/2010 10:03|     12431|Australia|              15.0|                   83.0|\n",
      "|01/12/2010 10:03|     12431|Australia|              15.0|                   47.0|\n",
      "|01/12/2010 10:03|     12431|Australia|              15.0|                   45.0|\n",
      "|01/12/2010 10:03|     12431|Australia|39.599999999999994|                   69.6|\n",
      "|01/12/2010 10:03|     12431|Australia|              25.4|                   80.0|\n",
      "|01/12/2010 10:03|     12431|Australia|              35.7|                  100.7|\n",
      "|01/12/2010 10:03|     12431|Australia|             17.85|                  78.95|\n",
      "|01/12/2010 10:03|     12431|Australia|              17.0|      70.55000000000001|\n",
      "|01/12/2010 10:03|     12431|Australia|              39.6|                  74.45|\n",
      "|01/12/2010 10:03|     12431|Australia|              17.0|                   73.6|\n",
      "|01/12/2010 10:03|     12431|Australia|              32.7|      89.30000000000001|\n",
      "|01/12/2010 10:03|     12431|Australia|              20.4|                   70.1|\n",
      "|01/12/2010 14:32|     19888|Australia|              5.06|                   5.06|\n",
      "|01/12/2010 14:32|     19888|Australia|             11.82|                  16.88|\n",
      "|01/12/2010 14:32|     19888|Australia|              5.06|     21.939999999999998|\n",
      "|01/12/2010 14:32|     19888|Australia|              1.66|                  18.54|\n",
      "|01/12/2010 14:32|     19888|Australia|             12.72|                  19.44|\n",
      "|01/12/2010 14:32|     19888|Australia|             20.34|                  34.72|\n",
      "+----------------+----------+---------+------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "# Show a new column related to Value that, for each invoice/row, \n",
    "# would contain the sum of n previous rows (of column Value)\n",
    "window_previous = -2 # how many days ago we want to start the sum\n",
    "window = Window.partitionBy('Country', 'CustomerID').orderBy('CustomerID', 'InvoiceDate').rowsBetween(window_previous, 0)\n",
    "# 'CustomerID', 'InvoiceDate', ascending=[True, True]\n",
    "df_invoice_value.withColumn('SumLastSalesForCustomer',F.sum('Value').over(window)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+---------+------------------+-------------------------+\n",
      "|     InvoiceDate|CustomerID|  Country|             Value|PreviousNValueForCustomer|\n",
      "+----------------+----------+---------+------------------+-------------------------+\n",
      "|01/12/2010 10:03|     12431|Australia|              51.0|                     NULL|\n",
      "|01/12/2010 10:03|     12431|Australia|              17.0|                     NULL|\n",
      "|01/12/2010 10:03|     12431|Australia|              15.0|                     51.0|\n",
      "|01/12/2010 10:03|     12431|Australia|              15.0|                     17.0|\n",
      "|01/12/2010 10:03|     12431|Australia|              15.0|                     15.0|\n",
      "|01/12/2010 10:03|     12431|Australia|39.599999999999994|                     15.0|\n",
      "|01/12/2010 10:03|     12431|Australia|              25.4|                     15.0|\n",
      "|01/12/2010 10:03|     12431|Australia|              35.7|       39.599999999999994|\n",
      "|01/12/2010 10:03|     12431|Australia|             17.85|                     25.4|\n",
      "|01/12/2010 10:03|     12431|Australia|              17.0|                     35.7|\n",
      "|01/12/2010 10:03|     12431|Australia|              39.6|                    17.85|\n",
      "|01/12/2010 10:03|     12431|Australia|              17.0|                     17.0|\n",
      "|01/12/2010 10:03|     12431|Australia|              32.7|                     39.6|\n",
      "|01/12/2010 10:03|     12431|Australia|              20.4|                     17.0|\n",
      "|01/12/2010 14:32|     19888|Australia|              5.06|                     NULL|\n",
      "|01/12/2010 14:32|     19888|Australia|             11.82|                     NULL|\n",
      "|01/12/2010 14:32|     19888|Australia|              5.06|                     5.06|\n",
      "|01/12/2010 14:32|     19888|Australia|              1.66|                    11.82|\n",
      "|01/12/2010 14:32|     19888|Australia|             12.72|                     5.06|\n",
      "|01/12/2010 14:32|     19888|Australia|             20.34|                     1.66|\n",
      "+----------------+----------+---------+------------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show a new column related to Value that, for each invoice/row, \n",
    "# would contain the value corresponding to a lag of some size (of column Value)\n",
    "window = Window.partitionBy('Country', 'CustomerID').orderBy('CustomerID', 'InvoiceDate')\n",
    "window_size = 2\n",
    "df_invoice_value.withColumn('PreviousNValueForCustomer',F.lag('Value', window_size).over(window)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task D - Spark SQL\n",
    "\n",
    "SQL operations to work with:\n",
    "- Storing the retail data as a persistent table\n",
    "- Use of SQL expressions to query the table, similarly to a DataFrame\n",
    "- Creating a temporary table and then as above query it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the retail data as persistent table into the Hive metastore\n",
    "df_retail.write.mode('overwrite').saveAsTable('RetailTable')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Database(name='default', catalog='spark_catalog', description='default database', locationUri='file:/home/jovyan/code/notebooks/spark-warehouse')]\n"
     ]
    }
   ],
   "source": [
    "# List of databases\n",
    "print(spark.catalog.listDatabases())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of tables in the default database\n",
    "spark.catalog.listTables(dbName='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column(name='InvoiceNo', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='StockCode', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='Description', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='Quantity', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='InvoiceDate', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='UnitPrice', description=None, dataType='double', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='CustomerID', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='Country', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of columns in the retail table\n",
    "spark.catalog.listColumns('retailtable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use of the default managed table\n",
    "spark.sql('USE default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+----------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate     |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------------------------------+--------+----------------+---------+----------+--------------+\n",
      "|536375   |71053    |WHITE METAL LANTERN                |6       |01/12/2010 09:32|3.39     |17850     |United Kingdom|\n",
      "|C536391  |21983    |PACK OF 12 BLUE PAISLEY TISSUES    |-24     |01/12/2010 10:24|0.29     |17548     |United Kingdom|\n",
      "|536395   |21314    |SMALL GLASS HEART TRINKET POT      |8       |01/12/2010 10:47|2.1      |13767     |United Kingdom|\n",
      "|536396   |82494L   |WOODEN FRAME ANTIQUE WHITE         |12      |01/12/2010 10:51|2.55     |17850     |United Kingdom|\n",
      "|536425   |22837    |HOT WATER BOTTLE BABUSHKA          |8       |01/12/2010 12:08|4.65     |13758     |United Kingdom|\n",
      "|536464   |20878    |SET/9 CHRISTMAS T-LIGHTS SCENTED   |1       |01/12/2010 12:23|1.25     |17968     |France        |\n",
      "|536520   |22760    |TRAY, BREAKFAST IN BED             |1       |01/12/2010 12:43|12.75    |14729     |United Kingdom|\n",
      "|536520   |22812    |PACK 3 BOXES CHRISTMAS PANNETONE   |3       |01/12/2010 12:43|1.95     |14729     |United Kingdom|\n",
      "|536530   |21071    |VINTAGE BILLBOARD DRINK ME MUG     |24      |01/12/2010 13:21|1.25     |17905     |France        |\n",
      "|536530   |22943    |CHRISTMAS LIGHTS 10 VINTAGE BAUBLES|2       |01/12/2010 13:21|4.95     |17905     |France        |\n",
      "|536544   |22812    |PACK 3 BOXES CHRISTMAS PANNETONE   |2       |01/12/2010 14:32|4.21     |19224     |United Kingdom|\n",
      "|536544   |47593B   |SCOTTIE DOGS BABY BIB              |2       |01/12/2010 14:32|0.85     |18657     |United Kingdom|\n",
      "|536551   |22551    |PLASTERS IN TIN SPACEBOY           |1       |01/12/2010 14:34|1.65     |17346     |United Kingdom|\n",
      "|536575   |15056P   |EDWARDIAN PARASOL PINK             |48      |01/12/2010 16:01|4.6      |13777     |United Kingdom|\n",
      "|536592   |21110    |LARGE CAKE TOWEL PINK SPOTS        |2       |01/12/2010 17:06|13.57    |18987     |United Kingdom|\n",
      "|536592   |21349    |IVY HEART WREATH                   |3       |01/12/2010 17:06|13.57    |18777     |United Kingdom|\n",
      "|536592   |22976    |CIRCUS PARADE CHILDRENS EGG CUP    |2       |01/12/2010 17:06|2.51     |18987     |United Kingdom|\n",
      "|C536391  |21984    |PACK OF 12 PINK PAISLEY TISSUES    |-24     |01/12/2010 10:24|0.29     |17548     |United Kingdom|\n",
      "|536398   |21980    |PACK OF 12 RED RETROSPOT TISSUES   |24      |01/12/2010 10:52|0.29     |13448     |United Kingdom|\n",
      "|536412   |21242    |RED RETROSPOT PLATE                |1       |01/12/2010 11:49|1.69     |17920     |United Kingdom|\n",
      "+---------+---------+-----------------------------------+--------+----------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the content of retail table\n",
    "spark.sql('SELECT ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary table with just the customers\n",
    "df_customers.createOrReplaceTempView('CustomersTable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|CustomerID|Country  |\n",
      "+----------+---------+\n",
      "|12431     |Australia|\n",
      "|19888     |Australia|\n",
      "|19997     |Australia|\n",
      "|20145     |Australia|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CustomerID and country in all rows, with rows order by customerID\n",
    "spark.sql(\"\"\"SELECT \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|Country       |count|\n",
      "+--------------+-----+\n",
      "|Germany       |4    |\n",
      "|France        |15   |\n",
      "|EIRE          |2    |\n",
      "|Norway        |2    |\n",
      "|Australia     |4    |\n",
      "|United Kingdom|100  |\n",
      "|Netherlands   |2    |\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counting of rows regarding each country registered\n",
    "spark.sql(\"\"\"SELECT Country, count(*) as count\"\"\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
